{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T09:19:20.350740Z",
     "start_time": "2021-04-09T09:19:20.342943Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competición kaggle\n",
    "\n",
    "# https://www.kaggle.com/c/the-bridge-nlp/data?select=train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y limpieza datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T09:19:22.281299Z",
     "start_time": "2021-04-09T09:19:22.251224Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T09:19:22.445958Z",
     "start_time": "2021-04-09T09:19:22.443132Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train[['target', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T09:19:23.128914Z",
     "start_time": "2021-04-09T09:19:22.855444Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def text_preproc(x):\n",
    "    x = x.lower()\n",
    "    x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
    "    x = x.encode('ascii', 'ignore').decode()\n",
    "    x = re.sub(r'https*\\S+', ' ', x)\n",
    "    x = re.sub(r'http*\\S+', ' ', x)\n",
    "    x = re.sub(r'@\\S+', ' ', x)\n",
    "    x = re.sub(r'#\\S+', ' ', x)\n",
    "    x = re.sub(r'\\'\\w+', '', x)\n",
    "    x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
    "    x = re.sub(r'\\w*\\d+\\w*', '', x)\n",
    "    x = re.sub(r'\\s{2,}', ' ', x)\n",
    "    return x\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(text_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T08:38:05.162982Z",
     "start_time": "2021-04-09T08:38:05.140431Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 deeds reason may allah forgive us\n",
      "1 forest fire near la ronge sask canada\n",
      "2 residents asked place notified officers evacuation shelter place orders expected\n",
      "3  update california hwy closed directions due lake county fire \n",
      "4 i top hill see fire woods \n",
      "5 three people died heat wave far\n",
      "6  bago myanmar arrived bago\n",
      "7 damage school bus multi car crash \n",
      "8 what man \n",
      "9 love fruits\n",
      "10 summer lovely\n",
      "11 car fast\n",
      "12 ridiculous \n",
      "13 london cool \n",
      "14 love skiing\n",
      "15 wonderful day \n",
      "16 nyc last week \n",
      "17 love girlfriend\n",
      "18 like pasta \n",
      "19 always try bring heavy \n",
      "20  breaking news nigeria flag set ablaze aba \n",
      "21 plus side look sky last night ablaze \n",
      "22  they built much hype around new acquisitions doubt set epl ablaze season \n",
      "23 inec office abia set ablaze \n",
      "24 barbados jamaica two cars set ablaze santa cruz head st elizabeth police superintende \n",
      "25 ablaze lord d\n",
      "26 check out \n",
      "27 outside ablaze alive\n",
      "but dead inside\n",
      "28 awesome time visiting cfc head office ancop site ablaze thanks tita vida taking care us \n",
      "29 wanted set chicago ablaze preaching hotel \n",
      "30 building perfect tracklist life leave streets ablaze\n",
      "31 check out \n",
      "32 deputies man shot brighton home set ablaze \n",
      "33 police arsonist deliberately set black church north carolinaablaze \n",
      "34 noches el bestia happy see teammates training hard goodnight gunners \n",
      "35 truck ablaze voortrekker ave outside tambo intl cargo section \n",
      "36 set hearts ablaze every city gift every skyline like kiss upon lips \n",
      "37 sky ablaze tonight los angeles i expecting ig fb filled sunset shots know peeps \n",
      "38 west burned thousands wildfires ablaze alone \n",
      "39 revel wmv videos means mac farewell ablaze wmv en route dvd gtxrwm\n",
      "40 progressive greetings in month students would set pens ablaze torch publications \n",
      "41 rene ablaze amp jacinta secret fallen skies edit mar \n",
      "42  steve fires something else california tinderbox clown setting ablaze \n",
      "43  rene ablaze amp ian buff magnitude \n",
      "44  time talk go until know make due work \n",
      "45  can kids cuz got bicycle accident amp split testicles impossible kids michael father\n",
      "46 accident i w traffic moving slower usual \n",
      "47 accident center lane blocked us nb great america pkwy \n",
      "48  speeding among top causes teen accidents car accident tee \n",
      "49 reported motor vehicle accident curry herman rd near stephenson involving overturned vehicle please use \n",
      "50 bigrigradio live accident awareness\n",
      "51 i mile marker south mooresville iredell vehicle accident ramp closed pm\n",
      "52 rt sleeping pills double risk car accident \n",
      "53  accident knew gon happen \n",
      "54 traffic accident n cabrillo hwy magellan av mir \n",
      "55 i mile marker south mooresville iredell vehicle accident congestion pm\n",
      "56 pastor scene accident who owner range rover \n",
      "57 horrible car accident past sunday i finally able get around thank god \n",
      "58 wait see pissed donnie tell another accident \n",
      "59  overturns interstate click crash gt \n",
      "60 accident left lane blocked rt nb eddy rd stop go traffic back nh delay mins \n",
      "61  accident property damage piner rd horndale dr\n",
      "62 suffield alberta accident \n",
      "63  mile backup i south accident blocking right lanes exit langtree rd consider nc nc nc alternate\n",
      "64 accident changed life help determine options financially support life care plans on going treatment \n",
      "65 car even week got fucking car accident mfs can fucking drive \n",
      "66  police previously died road accident killed explosion \n",
      "67 still heard church leaders kenya coming forward comment accident issue disciplinary measures \n",
      "68  scuf ps live game cya\n",
      "69  man drive effort gets painful man win roger bannister\n",
      "70  ir icemoon aftershock \n",
      "71  im speaking someone using scuf people end getting ps also \n",
      "72  harder conflict glorious triumph thomas paine\n",
      "73  going clay pigeon shooting crying \n",
      "74 aftershock \n",
      "75  ir icemoon aftershock \n",
      "76  ir icemoon aftershock \n",
      "77  ir icemoon aftershock \n",
      "78  i seeing issues aftershock \n",
      "79  ir icemoon aftershock \n",
      "80  ir icemoon aftershock \n",
      "81  bonus minute daily habits could really improve life many already do \n",
      "82 moment get scary roller coaster guy behind screaming bloody murder \n",
      "83 aftershock full streaming youtube \n",
      "84  gt gt aftershock protect profit next global financial \n",
      "85 sometimes face difficulties something wrong something right joel osteen\n",
      "86  thing stands dream try belief actually possible joel brown\n",
      "87 praise god ministry tells like is \n",
      "88  going die best way know avoid trap thinking something lose steve jobs\n",
      "89 tried orange aftershock today life never\n",
      "90  love bb\n",
      "91 aftershock \n",
      "92 aftershock back school kick great want thank everyone making possible great night \n",
      "93 experts france begin examining airplane debris found reunion island french air accident experts wedn \n",
      "94 family members osama bin laden died airplane accident ironic mhmmm gov shit suspect\n",
      "95 horrible accident man died wings airplane \n",
      "96 cessna airplane accident ocampo coahuila mexico july killed four men including state coahuila government official \n",
      "97  man died wings airplane \n",
      "98 experts france begin examining airplane debris found reunion island french air accident experts wednesday began examining t \n",
      "99  mbataweel family members killed airplane accident\n",
      "100 almost sent coworker nudes accident thank god airplane mode\n",
      "101  might killed airplane accident night car wreck politics best \n",
      "102 experts france begin examining airplane debris found reunion island french air accident experts on \n",
      "103 unbelievably insane \n",
      "104 horrible accident man died wings airplane \n",
      "105 usama bin ladins family dead airplane crash naturally accident \n",
      "106 pilot dies plane crash car festival via \n",
      "107 strict liability context airplane accident \n",
      "108 experts france begin examining airplane debris found reunion island french air accident experts wedn \n",
      "109 airplane accident \n",
      "110 phone looks like car ship airplane accident terrible\n",
      "111 airplane crashes house colombia people die accident \n",
      "112 shooting airplane accident \n",
      "113 could drone cause airplane accident pilots worried use drones esp close vicinity airports \n",
      "114  twelve feared killed pakistani air ambulance helicopter crash \n",
      "115 two air ambulances scene serious crash two cars lorry \n",
      "116 anyone travelling aberystwyth shrewsbury right there incident services halt outside shrews ambulance scene \n",
      "117 new nanotech device able target destroy blood clots \n",
      "118  hella crazy fights ambulance couple mosh pits \n",
      "119 get run ambulance lucky \n",
      "120  twelve feared killed pakistani air ambulance helicopter crash \n",
      "121  waiting ambulance\n",
      "122  ok need ambulance hahahah good \n",
      "123 ambulance sprinter automatic frontline vehicle choice lez compliant ebay \n",
      "124 pakistan air ambulance helicopter crash kills nine \n",
      "125  nissan ok need medical assistance call ambulance need\n",
      "126  ny emts petition per hour minimum wage \n",
      "127  twelve feared killed pakistani air ambulance helicopter crash \n",
      "128 twelve feared killed pakistani air ambulance helicopter crash \n",
      "129 ambulance sprinter automatic frontline vehicle choice lez compliant ebay \n",
      "130 know way ambulance coming lt lt \n",
      "131  twelve feared killed pakistani air ambulance helicopter crash \n",
      "132 ambulance right outside work\n",
      "133  dog thinks he ambulance \n",
      "134 happening hatzolah ems ambulance responding dual sirens and \n",
      "135  twelve feared killed pakistani air ambulance helicopter crash \n",
      "136  twelve feared killed pakistani air ambulance helicopter crash \n",
      "137 twelve feared killed pakistani air ambulance helicopter crash \n",
      "138 twelve feared killed pakistani air ambulance helicopter crash \n",
      "139  surprised still cannot standardised clinical practice across nhs ambulance trust \n",
      "140  twelve feared killed pakistani air ambulance helicopter crash \n",
      "141 episode trunks annihilated freiza cleanest shit ever showed nigga mercy \n",
      "142 shall annihilated petebests dessicated laid bare shall kneel me \n",
      "143 uribe annihilated baseball \n",
      "144  hey sundowns annihilated previous meeting celtic indeed improvement \n",
      "145  mizzou annihilated florida past seasons even ended muschamp career can compete bama\n",
      "146 annihilated abs \n",
      "147 annihilated status education mba behalf easy street careen eovm \n",
      "148  to luka die them everything annihilated alois trancy\n",
      "149 cop pulls drunk driver safety seconds car hit train via \n",
      "150 must annihilated \n",
      "151 cop pulls drunk driver safety seconds car hit train via \n",
      "152 one thing sure god promised israel annihilated but the horror iran w nukes \n",
      "153  oryx symbol arabian peninsula annihilated hunters \n",
      "154  to luka die them everything annihilated alois trancy \n",
      "155 ready get annihilated bucs game\n",
      "156  people last nights weather really philip thought would forecast that \n",
      "157 domain sophistication annihilated closely up to the minute feat zrnf\n",
      "158 completely annihilated cech paul keegan time alive\n",
      "159  annihilated legion itself survivors imperfect hybrid project quickly formed new secret cell\n",
      "160  exactly that lesnar cena match summerslam last year great brock annihilated guy who\n",
      "161 fun filled happy hour simmons bar camden handsome one i got annihilated apart game \n",
      "162  hell fraction belief total annihilation destruction usa \n",
      "163 u s national park services tonto national forest stop annihilation salt river wild horse via \n",
      "164 world annihilation vs self transformation aliens attack exterminate humans \n",
      "165  starmade stardate planetary annihilation via \n",
      "166 u s national park services tonto national forest stop annihilation salt river wild horse via \n",
      "167  please sign share petition save wild horses arizona \n",
      "168 u s national park services tonto national forest stop annihilation salt river wild horse via \n",
      "169 souls punished withannihilation \n",
      "170  mention major contributor annihilation israel\n",
      "171  need help horses die please rt amp sign petition take stand amp voice them \n",
      "172 reject laws misguided false prophets imprison nations fueling self annihilation\n",
      "173  need help horses die please rt amp sign petition take stand amp voice them \n",
      "174 hey sign petition save sing a long order \n",
      "175 u s national park services tonto national forest stop annihilation salt river wild horse via \n",
      "176 please sign amp rt save \n",
      "177 thanks dante join us following zone johnny \n",
      "178 world annihilation vs self transformation aliens attack exterminate humans \n",
      "179 u s national park services tonto national forest stop annihilation salt river wild horse via \n",
      "180 ohh fukurodani survive apocalypse bokuto feels horrible poor boy ppor child\n",
      "181 another jocelyn birthday apocalypse\n",
      "182 rt rt stephenscifi adaptation watch charlie human apocalypse optioned film \n",
      "183 another hour august here red rover zombie apocalypse \n",
      "184  feel like pull up one stages apocalypse \n",
      "185 kinda hot played radio today what next disease all apocalypse started everyone careful \n",
      "186 know question interpretation sign apocalypse called \n",
      "187 julie r apocalypse version romeo juliet \n",
      "188 rt fittscott minecraft night lucky block mod bob apocalypse wither amp more mod showcase popularmmos vi \n",
      "189 rt our mother mary short reading apocalypse in spirit angel took top enormous high mountain and \n",
      "190 candylit imagine sarumi zombie apocalypse fighting back back heart heart conversations the \n",
      "191 rt liked youtube video minecraft night lucky block mod bob apocalypse wither amp more mo \n",
      "192 that planet lone audience apocalypse \n",
      "193 dad bought dvd looks like science doc front read back actually impending biblical apocalypse\n",
      "194 go look grizzly peak right now looks like beginning dystopian apocalypse movie\n",
      "195 niece asked scared apocalypse here \n",
      "196 there storm cairo latest men apocalypse set photo via \n",
      "197 minecraft night lucky block mod bob apocalypse wither amp more mod showcase popularmmos via \n",
      "198 shot heart xv going totally give love bad name heart pierc \n",
      "199 latest reveals queen \n"
     ]
    }
   ],
   "source": [
    "#for i in range(0, 200):\n",
    "#    print(i, df_train['text'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento Lemmatizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T09:49:25.818893Z",
     "start_time": "2021-04-09T09:49:25.809903Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_train[['text']]\n",
    "y = df_train[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T09:49:26.225351Z",
     "start_time": "2021-04-09T09:49:26.063819Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def english_lemmatizer(x):\n",
    "    lemmer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmer.lemmatize(word) for word in x.split()])\n",
    "\n",
    "X['text'] = X['text'].apply(english_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T09:49:28.182356Z",
     "start_time": "2021-04-09T09:49:28.175519Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#Primera opción: Usando CountVectorizer y GridSearchCV\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('svm', SVC(probability=True))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': ([2.3]),\n",
    "    'vect__min_df': ([15]),\n",
    "    'vect__max_features': ([1500]),\n",
    "    'vect__ngram_range': ((1, 2), (1, 3)),\n",
    "    'svm__kernel': ('linear', 'rbf', 'sigmoid'),\n",
    "    'svm__C': (0.5, 1, 2),\n",
    "    'svm__gamma': ('scale', 'auto')\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "                          parameters,\n",
    "                          cv=3,\n",
    "                          n_jobs=-1,\n",
    "                          scoring='roc_auc') #Nos saca línea bajo al curva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segunda opción: Usando TfidfVectorizer y RandomizedSearchCV (la mejor combinación)\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('svm', SVC(probability=True))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': ([2.3]),\n",
    "    'vect__min_df': ([15]),\n",
    "    'vect__max_features': ([1500]),\n",
    "    'vect__ngram_range': ((1, 2), (1, 3)),\n",
    "    'svm__kernel': ('linear', 'rbf', 'sigmoid'),\n",
    "    'svm__C': (0.5, 1, 2),\n",
    "    'svm__gamma': ('scale', 'auto')\n",
    "}\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipeline,\n",
    "                          parameters,\n",
    "                          cv=3,\n",
    "                          n_jobs=-1,\n",
    "                          scoring='roc_auc') #Nos saca la línea bajo la curva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:11:16.428302Z",
     "start_time": "2021-04-09T09:49:30.521885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                                             ('svm', SVC(probability=True))]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'svm__C': (0.5, 1, 2),\n",
       "                                        'svm__gamma': ('scale', 'auto'),\n",
       "                                        'svm__kernel': ('linear', 'rbf',\n",
       "                                                        'sigmoid'),\n",
       "                                        'vect__max_df': [2.3],\n",
       "                                        'vect__max_features': [1500],\n",
       "                                        'vect__min_df': [15],\n",
       "                                        'vect__ngram_range': ((1, 2), (1, 3))},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X['text'], y['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:11:26.586727Z",
     "start_time": "2021-04-09T10:11:26.573090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'vect__ngram_range': (1, 3), 'vect__min_df': 15, 'vect__max_features': 1500, 'vect__max_df': 2.3, 'svm__kernel': 'sigmoid', 'svm__gamma': 'scale', 'svm__C': 0.5}\n",
      "\n",
      "Best auc: 0.7263076416991963\n",
      "\n",
      "Best model: Pipeline(steps=[('vect',\n",
      "                 TfidfVectorizer(max_df=2.3, max_features=1500, min_df=15,\n",
      "                                 ngram_range=(1, 3))),\n",
      "                ('svm', SVC(C=0.5, kernel='sigmoid', probability=True))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\", grid_search.best_params_)\n",
    "print()\n",
    "print(\"Best auc:\", grid_search.best_score_)\n",
    "print()\n",
    "print(\"Best model:\", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T07:48:50.404317Z",
     "start_time": "2021-04-09T07:48:50.401551Z"
    }
   },
   "source": [
    "## CONVERT DATA TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:11:49.595215Z",
     "start_time": "2021-04-09T10:11:49.570348Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_test = df_test[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:11:50.389119Z",
     "start_time": "2021-04-09T10:11:50.247601Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def text_preproc(x):\n",
    "    x = x.lower()\n",
    "    x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
    "    x = x.encode('ascii', 'ignore').decode()\n",
    "    x = re.sub(r'https*\\S+', ' ', x)\n",
    "    x = re.sub(r'http*\\S+', ' ', x)\n",
    "    x = re.sub(r'@\\S+', ' ', x)\n",
    "    x = re.sub(r'#\\S+', ' ', x)\n",
    "    x = re.sub(r'\\'\\w+', '', x)\n",
    "    x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
    "    x = re.sub(r'\\w*\\d+\\w*', '', x)\n",
    "    x = re.sub(r'\\s{2,}', ' ', x)\n",
    "    return x\n",
    "\n",
    "\n",
    "df_test['text'] = df_test['text'].apply(text_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:11:52.194072Z",
     "start_time": "2021-04-09T10:11:51.795024Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = grid_search.best_estimator_.predict_proba(df_test['text']) #usamos el predict_proba porque queremos saber la probabilidad de que sea un desastre 1 o no sea un\n",
    "#desastre 0. Nos genera un array de 2 columnas, nos tenemos que quedar con la segunda columna que es la que indica la probabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:12:57.413664Z",
     "start_time": "2021-04-09T10:12:57.394396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05096029, 0.94903971],\n",
       "       [0.86117074, 0.13882926],\n",
       "       [0.29861072, 0.70138928],\n",
       "       ...,\n",
       "       [0.14413476, 0.85586524],\n",
       "       [0.30109661, 0.69890339],\n",
       "       [0.14416623, 0.85583377]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:13:25.138363Z",
     "start_time": "2021-04-09T10:13:25.132834Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_pr = pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:13:52.094371Z",
     "start_time": "2021-04-09T10:13:52.081231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050960</td>\n",
       "      <td>0.949040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.861171</td>\n",
       "      <td>0.138829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.298611</td>\n",
       "      <td>0.701389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141774</td>\n",
       "      <td>0.858226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.308186</td>\n",
       "      <td>0.691814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>0.144145</td>\n",
       "      <td>0.855855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>0.144135</td>\n",
       "      <td>0.855865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>0.301097</td>\n",
       "      <td>0.698903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>0.144166</td>\n",
       "      <td>0.855834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2267 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1\n",
       "0     0.050960  0.949040\n",
       "1     0.861171  0.138829\n",
       "2     0.298611  0.701389\n",
       "3     0.141774  0.858226\n",
       "4     0.308186  0.691814\n",
       "...        ...       ...\n",
       "2262  0.144145  0.855855\n",
       "2263  0.245614  0.754386\n",
       "2264  0.144135  0.855865\n",
       "2265  0.301097  0.698903\n",
       "2266  0.144166  0.855834\n",
       "\n",
       "[2267 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:14:12.643666Z",
     "start_time": "2021-04-09T10:14:12.639431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.949040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.138829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.701389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.858226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.691814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>0.855855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>0.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>0.855865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>0.698903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>0.855834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2267 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1\n",
       "0     0.949040\n",
       "1     0.138829\n",
       "2     0.701389\n",
       "3     0.858226\n",
       "4     0.691814\n",
       "...        ...\n",
       "2262  0.855855\n",
       "2263  0.754386\n",
       "2264  0.855865\n",
       "2265  0.698903\n",
       "2266  0.855834\n",
       "\n",
       "[2267 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pr = df_test_pr.iloc[:,1:2]\n",
    "df_test_pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:14:22.185168Z",
     "start_time": "2021-04-09T10:14:22.166701Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_or = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:14:22.441935Z",
     "start_time": "2021-04-09T10:14:22.438876Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_04 = pd.DataFrame(df_test_or['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:14:25.385267Z",
     "start_time": "2021-04-09T10:14:25.381525Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_01 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:14:45.784311Z",
     "start_time": "2021-04-09T10:14:45.775570Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_01 = pd.concat([df_test_04, df_test_pr[1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:14:48.155923Z",
     "start_time": "2021-04-09T10:14:48.151301Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_01.set_index(['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:16:33.333293Z",
     "start_time": "2021-04-09T10:16:33.327281Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_01.rename(columns={1:'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:16:48.377357Z",
     "start_time": "2021-04-09T10:16:48.355878Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_01.to_csv('test_09.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T10:16:35.930536Z",
     "start_time": "2021-04-09T10:16:35.916796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.949040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.138829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.701389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.858226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.691814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10852</th>\n",
       "      <td>0.855855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10855</th>\n",
       "      <td>0.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10859</th>\n",
       "      <td>0.855865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10867</th>\n",
       "      <td>0.698903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10871</th>\n",
       "      <td>0.855834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2267 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target\n",
       "id             \n",
       "6      0.949040\n",
       "7      0.138829\n",
       "10     0.701389\n",
       "14     0.858226\n",
       "15     0.691814\n",
       "...         ...\n",
       "10852  0.855855\n",
       "10855  0.754386\n",
       "10859  0.855865\n",
       "10867  0.698903\n",
       "10871  0.855834\n",
       "\n",
       "[2267 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_01"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "338.4px",
    "left": "288px",
    "right": "20px",
    "top": "147px",
    "width": "342px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
